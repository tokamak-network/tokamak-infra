alertmanager:
  config:
    global:
      # Also possible to place this URL in a file.
      # Ex: `slack_api_url_file: '/etc/alertmanager/slack_url'`
      slack_api_url: 'https://hooks.slack.com/services/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'

    route:
      receiver: no-alert
      routes:
        - matchers:
            - group = tokamak
            - severity_resolved = info
          receiver: slack-notifications-resolve
          group_by: ['alertname']
          group_wait: 0s
          group_interval: 10s
          repeat_interval: 1h
        - matchers:
            - group = tokamak
          receiver: slack-notifications
          group_by: ['alertname']
          group_wait: 0s
          group_interval: 10s
          repeat_interval: 1h

    receivers:
      - name: no-alert
      - name: slack-notifications
        slack_configs:
          - channel: 'thanos-testnet-status'
            title: "{{ range .Alerts }}[Thanos Sepolia Test] {{ .Labels.app }}\n{{ end }}"
            text: "{{ range .Alerts }}[{{ .Labels.severity }}] {{ .Annotations.message }}\n{{ end }}"
      - name: slack-notifications-resolve
        slack_configs:
          - channel: 'thanos-testnet-status'
            send_resolved: true
            title: "{{ range .Alerts }}[Thanos Sepolia Test] {{ .Labels.app }}\n{{ end }}"
            text: "{{ range .Alerts }}{{ if eq .Status \"firing\" }}[{{ .Labels.severity }}] {{ .Annotations.message }} {{ else }}[{{ .Labels.severity_resolved }}] {{ .Annotations.message_resolved }} {{ end }}\n{{ end }}"

additionalPrometheusRulesMap:
  rule-name:
    groups:
      - name: 'op-geth'
        rules:
          - alert: 'op-geth down'
            labels:
              group: tokamak
              app: op-geth
              severity: critical
              severity_resolved: info
            expr: 'absent(up{job="op-geth"} == 1)'
            annotations:
              message: 'op-geth is down'
              message_resolved: 'op-geth is up'
      - name: 'op-node'
        rules:
          - alert: 'op-node down'
            labels:
              group: tokamak
              app: op-node
              severity: critical
              severity_resolved: info
            expr: 'absent(up{job="op-node"} == 1)'
            annotations:
              message: 'op-node is down'
              message_resolved: 'op-node is up'
      - name: 'op-batcher'
        rules:
          - alert: 'op-batcher down'
            labels:
              group: tokamak
              app: op-batcher
              severity: critical
              severity_resolved: info
            expr: 'absent(up{job="op-batcher"} == 1)'
            annotations:
              message: 'op-batcher is down'
              message_resolved: 'op-batcher is up'
      - name: 'op-proposer'
        rules:
          - alert: 'op-proposer down'
            labels:
              group: tokamak
              app: op-proposer
              severity: critical
              severity_resolved: info
            expr: 'absent(up{job="op-proposer"} == 1)'
            annotations:
              message: 'op-proposer is down'
              message_resolved: 'op-proposer is up'
      - name: 'proxyd down'
        rules:
          - alert: 'proxyd down'
            labels:
              group: tokamak
              app: proxyd
              severity: critical
              severity_resolved: info
            expr: 'absent(up{job="proxyd"} == 1)'
            annotations:
              message: 'proxyd is down'
              message_resolved: 'proxyd is up'
      - name: 'proxyd unhealthy'
        rules:
          - alert: 'proxyd unhealthy'
            labels:
              group: tokamak
              app: proxyd
              severity: critical
              severity_resolved: info
            expr: 'absent(probe_success{job="blackbox-eth-block-number", target="http://proxyd-svc.thanos:8545"} == 1)'
            annotations:
              message: 'proxyd is unhealthy'
              message_resolved: 'proxyd is healthy'
      - name: 'office l1'
        rules:
          - alert: 'office l1 unhealthy'
            for: 1m
            labels:
              group: tokamak
              app: l1
              severity: critical
              severity_resolved: info
            expr: 'absent(probe_success{job="blackbox-eth-block-number", target="https://sepolia.rpc.tokamak.network"} == 1)'
            annotations:
              message: 'office l1 unhealthy'
              message_resolved: 'office l1 is healthy'
      - name: 'blockscout'
        rules:
          - alert: 'blockscout'
            labels:
              group: tokamak
              app: blockscout
              severity: critical
              severity_resolved: info
            expr: 'absent(up{job="blockscout"} == 1)'
            annotations:
              message: 'blockscout is down'
              message_resolved: 'blockscout is up'
      - name: 'redis unhealthy'
        rules:
          - alert: 'redis unhealthy'
            labels:
              group: tokamak
              app: redis
              severity: critical
              severity_resolved: info
            expr: 'absent(probe_success{target="redis-svc.redis:6379"} == 1)'
            annotations:
              message: 'redis is unhealthy'
              message_resolved: 'redis is healthy'
      # - name: 'sequencer balance'
      #   rules:
      #     - alert: 'sequencer balance'
      #       labels:
      #         group: tokamak
      #         app: batch-submitter
      #         severity: critical
      #       expr: 'probe_success{job="blackbox-eth-node-synced",target="https://rpc.tokamak.network"} == 1 and on() (batch_submitter_sequencer_balance_eth < 0.2 and batch_submitter_sequencer_balance_eth != 0)'
      #       annotations:
      #         message: "sequencer balance is lower than 0.2 ether\nsequencer balance: {{ printf \"batch_submitter_sequencer_balance_eth{instance=~'.*'}\" | query | first | value }} eth"
      # - name: 'proposer balance'
      #   rules:
      #     - alert: 'proposer balance'
      #       labels:
      #         group: tokamak
      #         app: batch-submitter
      #         severity: critical
      #       expr: 'probe_success{job="blackbox-eth-node-synced",target="https://rpc.tokamak.network"} == 1 and on() (batch_submitter_proposer_balance_eth < 0.2 and batch_submitter_proposer_balance_eth != 0)'
      #       annotations:
      #         message: "proposer balance is lower than 0.2 ether\nproposer balance: {{ printf \"batch_submitter_proposer_balance_eth{instance=~'.*'}\" | query | first | value }} eth"
      # - name: 'mismatch the block number between CTC and L2 block head'
      #   rules:
      #     - alert: 'mismatch the block number between CTC and L2 block head'
      #       labels:
      #         group: tokamak
      #         app: batch-submitter
      #         severity: critical
      #         severity_resolved: info
      #       # the end value of sequencer is exclusive.
      #       # end = l2LatestBlockNumber + 1
      #       # ref: https://github.com/tokamak-network/tokamak-titan/blob/main/batch-submitter/drivers/sequencer/driver.go#L144
      #       expr: 'chain_head_block{job="l2geth"} - on () batch_submitter_sequencer_block_number{job="batch-submitter"} != -1'
      #       for: 20m
      #       annotations:
      #         message: "CTC: Mismatch detected between chain_head_block (job=l2geth): {{ \"chain_head_block{job='l2geth'}\" | query | first | value | printf \"%.0f\" }}\n batch_submitter_sequencer_block_number: {{ \"batch_submitter_sequencer_block_number{job='batch-submitter'}\" | query | first | value | printf \"%.0f\"  }}"
      #         message_resolved: 'CTC: The mismatched detected between chain_head_block (job=l2geth) and batch_submitter_sequencer_block_number has been resolved'
      # - name: 'mismatch the block number between SCC and L2 block head'
      #   rules:
      #     - alert: 'mismatch the block number between SCC and L2 block head'
      #       labels:
      #         group: tokamak
      #         app: batch-submitter
      #         severity: critical
      #         severity_resolved: info
      #       expr: 'chain_head_block{job="l2geth"} - on () batch_submitter_proposer_block_number{job="batch-submitter"} != -1'
      #       for: 30m
      #       annotations:
      #         message: "SCC: Mismatch detected between chain_head_block (job=l2geth): {{ \"chain_head_block{job='l2geth'}\" | query | first | value | printf \"%.0f\" }}\n batch_submitter_proposer_block_number: {{ \"batch_submitter_proposer_block_number{job='batch-submitter'}\" | query | first | value | printf \"%.0f\"  }}"
      #         message_resolved: 'SCC: The mismatched detected between chain_head_block (job=l2geth) and batch_submitter_proposer_block_number has been resolved'
