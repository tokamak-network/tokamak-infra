alertmanager:
  config:
    global:
      # Also possible to place this URL in a file.
      # Ex: `slack_api_url_file: '/etc/alertmanager/slack_url'`
      slack_api_url: 'https://hooks.slack.com/services/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'

    route:
      receiver: no-alert
      routes:
        - matchers:
            - class = instatus
            - app = l2geth
          receiver: l2geth-instatus
          group_by: ['instatus']
          group_wait: 0s
          group_interval: 10s
          repeat_interval: 1h
          continue: true
        - matchers:
            - class = instatus
            - app = l2geth-replica
          receiver: l2geth-replica-instatus
          group_by: ['instatus']
          group_wait: 0s
          group_interval: 10s
          repeat_interval: 1h
          continue: true
        - matchers:
            - class = instatus
            - app = data-transport-layer
          receiver: data-transport-layer-instatus
          group_by: ['instatus']
          group_wait: 0s
          group_interval: 10s
          repeat_interval: 1h
          continue: true
        - matchers:
            - class = instatus
            - app = tx-batch-submitter
          receiver: tx-batch-submitter-instatus
          group_by: ['instatus']
          group_wait: 0s
          group_interval: 10s
          repeat_interval: 1h
          continue: true
        - matchers:
            - class = instatus
            - app = state-batch-submitter
          receiver: state-batch-submitter-instatus
          group_by: ['instatus']
          group_wait: 0s
          group_interval: 10s
          repeat_interval: 1h
          continue: true
        - matchers:
            - class = instatus
            - app = l1
          receiver: l1-instatus
          group_by: ['instatus']
          group_wait: 0s
          group_interval: 10s
          repeat_interval: 1h
          continue: true
        - matchers:
            - class = instatus
            - app = block-explorer
          receiver: block-explorer-instatus
          group_by: ['instatus']
          group_wait: 0s
          group_interval: 10s
          repeat_interval: 1h
          continue: true
        - matchers:
            - group = tokamak
            - severity_resolved = info
          receiver: slack-notifications-resolve
          group_by: ['alertname']
          group_wait: 0s
          group_interval: 10s
          repeat_interval: 1h
        - matchers:
            - group = tokamak
          receiver: slack-notifications
          group_by: ['alertname']
          group_wait: 0s
          group_interval: 10s
          repeat_interval: 1h

    receivers:
      - name: no-alert
      - name: slack-notifications
        slack_configs:
          - channel: '#optimism-alarm-logs'
            title: "{{ range .Alerts }}[Titan Mainnet] {{ .Labels.app }}\n{{ end }}"
            text: "{{ range .Alerts }}[{{ .Labels.severity }}] {{ .Annotations.message }}\n{{ end }}"
      - name: slack-notifications-resolve
        slack_configs:
          - channel: '#optimism-alarm-logs'
            send_resolved: true
            title: "{{ range .Alerts }}[Titan Mainnet] {{ .Labels.app }}\n{{ end }}"
            text: "{{ range .Alerts }}{{ if eq .Status \"firing\" }}[{{ .Labels.severity }}] {{ .Annotations.message }} {{ else }}[{{ .Labels.severity_resolved }}] {{ .Annotations.message_resolved }} {{ end }}\n{{ end }}"
      - name: l2geth-instatus
        webhook_configs:
          - url: 'https://api.instatus.com/v3/integrations/prometheus/clzkmeqcg741206hioodw72n6w1'
            send_resolved: true
      - name: l2geth-replica-instatus
        webhook_configs:
          - url: 'https://api.instatus.com/v3/integrations/prometheus/clzkmev7s727619hbooz4zqumdl'
            send_resolved: true
      - name: data-transport-layer-instatus
        webhook_configs:
          - url: 'https://api.instatus.com/v3/integrations/prometheus/clzkmezky710577i8ook2c158nd'
            send_resolved: true
      - name: tx-batch-submitter-instatus
        webhook_configs:
          - url: 'https://api.instatus.com/v3/integrations/prometheus/clzkmf5h3710710i8oo00mxtfnb'
            send_resolved: true
      - name: state-batch-submitter-instatus
        webhook_configs:
          - url: 'https://api.instatus.com/v3/integrations/prometheus/clzkmf9pl741381hiooggbk9tjd'
            send_resolved: true
      - name: l1-instatus
        webhook_configs:
          - url: 'https://api.instatus.com/v3/integrations/prometheus/clzkmeihd727264hboo7aldzitn'
            send_resolved: true
      - name: block-explorer-instatus
        webhook_configs:
          - url: 'https://api.instatus.com/v3/integrations/prometheus/clzkrjogj768723hioojs1873ev'
            send_resolved: true

additionalPrometheusRulesMap:
  rule-name:
    groups:
      - name: 'l2geth'
        rules:
          - alert: 'l2geth down'
            labels:
              group: tokamak
              class: instatus
              app: l2geth
              severity: critical
              severity_resolved: info
            expr: 'absent(up{job="l2geth"} == 1)'
            annotations:
              message: 'l2geth is down'
              message_resolved: 'l2geth is up'
      - name: 'l2geth-replica'
        rules:
          - alert: 'l2geth-replica down'
            labels:
              group: tokamak
              class: instatus
              app: l2geth-replica
              severity: critical
              severity_resolved: info
            expr: 'absent(up{job="l2geth-replica"} == 1)'
            annotations:
              message: 'l2geth-replica is down'
              message_resolved: 'l2geth-replica is up'
      - name: 'data-transport-layer'
        rules:
          - alert: 'data-transport-layer down'
            labels:
              group: tokamak
              class: instatus
              app: data-transport-layer
              severity: critical
              severity_resolved: info
            expr: 'absent(up{job="data-transport-layer"} == 1)'
            annotations:
              message: 'data-transport-layer is down'
              message_resolved: 'data-transport-layer is up'
      - name: 'tx-batch-submitter'
        rules:
          - alert: 'tx-batch-submitter down'
            labels:
              group: tokamak
              class: instatus
              app: tx-batch-submitter
              severity: critical
              severity_resolved: info
            expr: 'absent(up{job="tx-batch-submitter"} == 1)'
            annotations:
              message: 'tx-batch-submitter is down'
              message_resolved: 'tx-batch-submitter is up'
      - name: 'state-batch-submitter'
        rules:
          - alert: 'state-batch-submitter down'
            labels:
              group: tokamak
              app: state-batch-submitter
              class: instatus
              severity: critical
              severity_resolved: info
            expr: 'absent(up{job="state-batch-submitter"} == 1)'
            annotations:
              message: 'state-batch-submitter is down'
              message_resolved: 'state-batch-submitter is up'
      - name: 'proxyd down'
        rules:
          - alert: 'proxyd down'
            labels:
              group: tokamak
              app: proxyd
              severity: critical
              severity_resolved: info
            expr: 'absent(up{job="proxyd"} == 1)'
            annotations:
              message: 'proxyd is down'
              message_resolved: 'proxyd is up'
      - name: 'proxyd unhealthy'
        rules:
          - alert: 'proxyd unhealthy'
            labels:
              group: tokamak
              app: proxyd
              severity: critical
              severity_resolved: info
            expr: 'absent(probe_success{target="http://proxyd-svc.titan:8545"} == 1)'
            annotations:
              message: 'proxyd is unhealthy'
              message_resolved: 'proxyd is healthy'
      - name: 'office l1'
        rules:
          - alert: 'office l1 unhealthy'
            for: 1m
            labels:
              group: tokamak
              class: instatus
              app: l1
              severity: critical
              severity_resolved: info
            expr: 'absent(probe_success{job="blackbox-eth-block-number", target="https://rpc.tokamak.network"} == 1)'
            annotations:
              message: 'office l1 unhealthy'
              message_resolved: 'office l1 is healthy'
      - name: 'block-explorer'
        rules:
          - alert: 'block-explorer'
            labels:
              group: tokamak
              class: instatus
              app: block-explorer
              severity: critical
              severity_resolved: info
            expr: 'absent(probe_success{target="http://blockscout-svc.app-blockscout"} == 1)'
            annotations:
              message: 'block-explorer is down'
              message_resolved: 'block-explorer is up'
      - name: 'redis unhealthy'
        rules:
          - alert: 'redis unhealthy'
            labels:
              group: tokamak
              app: redis
              severity: critical
              severity_resolved: info
            expr: 'absent(probe_success{target="redis-svc.redis:6379"} == 1)'
            annotations:
              message: 'redis is unhealthy'
              message_resolved: 'redis is healthy'
      - name: 'sequencer balance'
        rules:
          - alert: 'sequencer balance'
            labels:
              group: tokamak
              app: tx-batch-submitter
              severity: critical
            expr: 'probe_success{job="blackbox-eth-node-synced",target="https://rpc.tokamak.network"} == 1 and on() (batch_submitter_sequencer_balance_eth{job="tx-batch-submitter"} < 0.2 and batch_submitter_sequencer_balance_eth{job="tx-batch-submitter"} != 0)'
            annotations:
              message: "sequencer balance is lower than 0.2 ether\nsequencer balance: {{ printf \"batch_submitter_sequencer_balance_eth{job='tx-batch-submitter'}\" | query | first | value }} eth"
      - name: 'proposer balance'
        rules:
          - alert: 'proposer balance'
            labels:
              group: tokamak
              app: state-batch-submitter
              severity: critical
            expr: 'probe_success{job="blackbox-eth-node-synced",target="https://rpc.tokamak.network"} == 1 and on() (batch_submitter_proposer_balance_eth{job="state-batch-submitter"} < 0.2 and batch_submitter_proposer_balance_eth{job="state-batch-submitter"} != 0)'
            annotations:
              message: "proposer balance is lower than 0.2 ether\nproposer balance: {{ printf \"batch_submitter_proposer_balance_eth{job='state-batch-submitter'}\" | query | first | value }} eth"
      - name: 'mismatch the block number between CTC and L2 block head'
        rules:
          - alert: 'mismatch the block number between CTC and L2 block head'
            labels:
              group: tokamak
              app: tx-batch-submitter
              severity: critical
              severity_resolved: info
            # the end value of sequencer is exclusive.
            # end = l2LatestBlockNumber + 1
            # ref: https://github.com/tokamak-network/tokamak-titan/blob/main/batch-submitter/drivers/sequencer/driver.go#L144
            expr: 'chain_head_block{job="l2geth"} - on () batch_submitter_sequencer_block_number{job="tx-batch-submitter"} != -1'
            for: 30m
            annotations:
              message: "CTC: Mismatch detected between chain_head_block (job=l2geth): {{ \"chain_head_block{job='l2geth'}\" | query | first | value | printf \"%.0f\" }}\n batch_submitter_sequencer_block_number: {{ \"batch_submitter_sequencer_block_number{job='tx-batch-submitter'}\" | query | first | value | printf \"%.0f\"  }}"
              message_resolved: 'CTC: The mismatched detected between chain_head_block (job=l2geth) and batch_submitter_sequencer_block_number has been resolved'
      - name: 'mismatch the block number between SCC and L2 block head'
        rules:
          - alert: 'mismatch the block number between SCC and L2 block head'
            labels:
              group: tokamak
              app: state-batch-submitter
              severity: critical
              severity_resolved: info
            expr: 'chain_head_block{job="l2geth"} - on () batch_submitter_proposer_block_number{job="state-batch-submitter"} != -1'
            for: 370m
            annotations:
              message: "SCC: Mismatch detected between chain_head_block (job=l2geth): {{ \"chain_head_block{job='l2geth'}\" | query | first | value | printf \"%.0f\" }}\n batch_submitter_proposer_block_number: {{ \"batch_submitter_proposer_block_number{job='state-batch-submitter'}\" | query | first | value | printf \"%.0f\"  }}"
              message_resolved: 'SCC: The mismatched detected between chain_head_block (job=l2geth) and batch_submitter_proposer_block_number has been resolved'
